[DEFAULT]
test_number = 2
process_number = 32
dataset_dir = ../dataset/
result_dir = ../result/
project_dir = ; fill this, eg: ../../defects4j/tmp/lang_1_buggy
max_rounds = 1
TIMEOUT = 30
MAX_PROMPT_TOKENS = 2048
MIN_ERROR_TOKENS = 500
PROMPT_TEMPLATE_NO_DEPS = d1_4.jinja2
PROMPT_TEMPLATE_DEPS = d3_4.jinja2
PROMPT_TEMPLATE_ERROR = error_3.jinja2

LANGUAGE = java
GRAMMAR_FILE = ; fill this, eg: ../../tree-sitter-java/java-grammar.so
COBERTURA_DIR = ./dependencies/cobertura-2.1.1
JUNIT_JAR = ./dependencies/lib/junit-platform-console-standalone-1.9.2.jar
MOCKITO_JAR = ./dependencies/lib/mockito-core-3.12.4.jar:./dependencies/lib/mockito-inline-3.12.4.jar:./dependencies/lib/mockito-junit-jupiter-3.12.4.jar:./dependencies/lib/byte-buddy-1.14.4.jar:./dependencies/lib/byte-buddy-agent-1.14.4.jar:./dependencies/lib/objenesis-3.3.jar
LOG4J_JAR = ./dependencies/lib/slf4j-api-1.7.5.jar:./dependencies/lib/slf4j-log4j12-1.7.12.jar:./dependencies/lib/log4j-1.2.17.jar
JACOCO_AGENT = ./dependencies/jacoco/jacocoagent.jar
JACOCO_CLI = ./dependencies/jacoco/jacococli.jar
REPORT_FORMAT = xml

[llm]
model_path = ; fill this, eg: ../../llm/codellama/CodeLlama-7b-Instruct
tokenizer_path = ; fill this, eg: ../../llm/codellama/CodeLlama-7b-Instruct/tokenizer.model
max_seq_len = 2048
max_batch_size = 4
temperature = 0.2
top_p = 0.95
frequency_penalty = 0
presence_penalty = 0

[openai]
api_keys = []
model = gpt-3.5-turbo
temperature = 0.5
top_p = 0.95
frequency_penalty = 0
presence_penalty = 0

[database]
host = localhost
port = 3306
database = ; fill this, any name.
user = ; fill this, preferably root
password = ; fill this

